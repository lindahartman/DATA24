---
title: "Data Literacy with Python"
---


## VIDEO 1 {studio} ~ 12  min

Welcome to Data Literacy with Python! 

Let me ask you something: Can you imagine living in today’s world but being unable to read? Think about it—street signs wouldn’t make sense, advertisements would just be noise, and most of the internet? Completely out of reach.

Now, even with videos and voice assistants everywhere, written text is still the backbone of how we communicate and navigate life. Without it, you'd feel lost.

But here’s the thing: today’s world doesn’t just run on words. It runs on data.

Every day, we’re creating over 400 million terabytes of data. That’s every single day. And here’s a wild stat—90% of all the world’s data was created in just the last two years.

This explosion of information is transforming how we make decisions, whether it’s in business, science, or society as a whole. To keep up, you need to know how to make sense of it.

Data isn’t just numbers on a screen—it’s stories waiting to be uncovered. And understanding data has become just as important as being able to read or write.

That’s where this course comes in.

We’re going to teach you how to take raw, messy data and turn it into something meaningful. You’ll work with rectangular data—the kind you find in spreadsheets or databases.

And don’t worry—this isn’t just about crunching numbers. It’s about answering real-world questions, solving problems, and making decisions based on insights you uncover.

By the end of this course, you’ll have the skills to transform data into knowledge.

Let’s talk about the tools you need to work with data.

You might be tempted by low-code or no-code solutions—those point-and-click interfaces that make everything seem so easy. And sure, they’re great for quick wins. But when it comes to serious data analysis, they have some big limitations.

Data analysis isn’t just about getting answers—it’s about getting **credible** answers.

To trust your insights, you need to leave a trail. Think about it—during analysis, you make dozens of tiny decisions:

- Which part of the data should you focus on?
- What variables should you use?
- Which patterns caught your eye?

Every decision shapes your results. And if you—or anyone else—can’t retrace those steps, how can you be sure your conclusions hold up?

That’s why scripting your analysis is so important.

With a script, every step is recorded. You can spot mistakes, refine your work, or pick up right where you left off—even months later. Low-code tools? They don’t give you that kind of transparency.

So, what’s the best language for scripting your data analysis?

The answer is Python.

Python is the world’s most popular programming language, and for good reason. Created in 1990 by Guido van Rossum, Python has become the go-to language for everything from building websites to powering cutting-edge AI. It may not be the fastest language out there, but it’s arguably the most readable. And in today’s data-driven world, readability matters more than ever. 

The Python ecosystem for data analysis is enormous. Whatever your question, there’s a good chance Python has a library—or ten—that can help.

Data analysis is unique—it’s less about traditional programming and more about crafting a story with your data. Your code should be clear and intuitive, not just for you, but for *anyone* who needs to understand your work. And that includes “future you”—because six months from now, you might not even recognize your own analysis without clear documentation!

So, as we dive into this course, we’ll emphasize simplicity, transparency, and readability. Because great analysis isn’t just about crunching numbers—it’s about telling a story that stands the test of time.

Data analysis is evolving. Today, some of the most cutting-edge tools are built on high-performance programming languages like Rust, Java, or C++. Why? Because these languages are fast—lightning fast. But here’s the best part: you don’t need to write in these languages to enjoy their benefits.

Modern tools now separate the user interface from the engine. That means the algorithms working behind the scenes are the same, no matter which scripting language you use.

Initiatives like Apache Arrow go even further—they create standardized data formats, making it easy to move between tools and platforms without losing performance or compatibility.

In this course, we’re diving into tools built on Rust—one of the fastest, most efficient programming languages out there. Specifically, we’ll use `uv` for managing packages and environments and polars for data wrangling.

These tools are not just fast—they’re scalable.

The examples we’ll explore together are small—easy to follow and understand. But don’t let that fool you. The same tools we use here can scale effortlessly to handle datasets with billions of rows, processed across dozens of parallel machines.

What’s even better? The interface doesn’t change.

So whether you’re working on a personal project, academic research, or a large-scale business application, the skills you gain here will translate directly to the real world.

The datasets may be small, but the questions and challenges we tackle are universal. By the end of this course, you’ll be equipped to uncover meaningful insights from your own data, no matter its size or complexity.

Let’s get started on this exciting journey into the world of data literacy!


# VIDEO 2 {studio} ~ 7 min

<!-- ## Shell -->

Before we dive into the thrilling world of data analysis, let’s pause and talk about something fundamental: your computer. That’s right, the device you’re watching this on is more than just a tool—it’s the backbone of your data analysis journey. Set it up well, and it will help you create reliable, reproducible, and stunning analytic projects.

But to unlock its full potential, we need to talk about something that might not look exciting at first glance but is incredibly powerful: the command line—also known as the shell or terminal.

Every operating system has some version of a terminal. Whether you're on Windows, macOS, or Linux, this is your gateway to greater control over your computer. In the terminal, you don’t rely on menus, buttons, or icons. Instead, you type commands, giving you direct access to your system's capabilities.

Now, if this is new to you, don’t worry! Below this video, you’ll find instructions on how to locate and open the terminal on your operating system. Take a moment to familiarize yourself with launching it, and then meet me back here.

Once you’re ready, we’ll discuss folders—yes, the simple yet crucial task of organizing your files. If you already know how to navigate your operating system, create new folders, and understand the user directory, feel free to skip ahead to the next video. Otherwise, stick with me, and I’ll walk you through everything you need to know.

Find and open the terminal on your computer. Take that first step toward becoming a power user!

<!-- :::{.challenge}
Find and open the terminal on your computer.
::: -->

<!-- ## On files and folders -->

Now that you’ve found your terminal, it’s time to talk about something fundamental to every data analysis project: files and folders.

Think about how your computer organizes everything you create or download—whether it’s a Word document, an Excel spreadsheet, or a photo. These files are stored in folders, and if you’ve ever saved something important, you know how critical it is to remember where it’s located.

When working with data analysis, you’ll generate a lot of files—scripts, datasets, reports, visualizations—the list goes on. Keeping all of these files organized and in one place is essential to staying productive. You don’t want to waste time hunting through your computer every time you need something.

Here’s the good news: your operating system already provides a great tool for organizing files—folders. Folders, or as they are sometimes called directories, are like containers, and they can even hold other folders. Picture this as a tree, with your main folder as the trunk and subfolders branching out.

Let’s take a moment to explore this on your computer.

- On Windows, you can open File Explorer by clicking the icon on your taskbar or pressing the Windows key + E. Once it’s open, you’ll see something like this:

<!-- ![](img/win_explorer.png) -->

- On Mac, you’ll use an app called Finder. Just click its icon in the Dock, and you’ll see a view like this:

<!-- ![](img/mac_finder.png) -->

- On Linux, it’s often just called Files, and the interface may vary depending on your distribution. On my Ubuntu setup, it looks like this:

<!-- ![](img/linux-files.png) -->

Inside these interfaces, folders are easy to spot with their distinct icons. Click on one, and you’ll dive inside to see its contents—maybe more files, maybe more folders.

Now, every operating system has a home base for your personal files. This is typically called your Home folder and contains directories like Music, Pictures, Videos, and Downloads. A special folder called Desktop displays its contents right on your screen.

While it’s tempting to store everything on your Desktop for easy access, this isn’t the best long-term solution. A cluttered Desktop can make it harder to stay organized, and let’s be honest—it doesn’t look great either.

<!-- ![](img/desktop.jpeg) -->

Instead, consider creating a dedicated folder for your data analysis projects. For example, you could use your Documents folder or create a new folder called Projects. If your Documents folder is synced to the cloud—like with OneDrive or iCloud—think carefully about whether that’s the right place for large datasets. Cloud storage is precious, and you might want to save that space for smaller files like presentations or text documents.

Don’t worry about backups just yet—we’ll cover that later when we dive into version control using Git and GitHub. For now, focus on picking a location that’s tidy, accessible, and works for you.

Once you’ve chosen your perfect home base, we’ll move on to the next step: learning how to navigate your files and folders using the command line. Trust me, it’s easier than it sounds, and it will make your workflow so much more efficient!

# VIDEO 3 {studio} ~ 6 min
<!-- ## Navigating in the command line -->

Alright, let’s open up your terminal! Don’t worry—this is not as intimidating as it might look. I’m going to guide you through some simple steps that will help you make sense of this dark text window, and these skills will serve you every time you use the command line.

First, take a look at your screen. See that little blinking line? That’s called the cursor, and it’s where you will type commands. To the left of the cursor, you’ll notice something else—this is called the system prompt. It’s a little symbol or combination of symbols, like $, >, or %. Think of it as your computer saying, “I’m ready for your command, Master!”

But before you start typing anything, let’s ask an important question: “Where am I?”. Not in terms of geography, but in terms of files and folders on your computer.

When you open your terminal, it starts in a specific location in your computer’s file system. This location is called a directory, and it’s similar to a folder in your file explorer. But which folder or directory are you in right now?

Here’s your first and perhaps most important command: `pwd`. It stands for “print working directory.” This command tells you the exact path of the folder your terminal is currently in.

If you’re using Windows, the equivalent command is `cd`—which we’ll use a bit differently later on, but for now, you can think of it as “current directory.”

Go ahead and type pwd (or cd on Windows) and hit Enter. Your terminal will respond with something called a path. This is a series of folder names separated by forward slashes /, and on Windows, you might also see a drive letter like C: or D:.

For example, my terminal tells me this:

<!-- 
```
Dmytro@dell-xps-9570: $ pwd  
/home/Dmytro  
``` 
-->

This means my terminal has opened in my user directory, /home/Dmytro/. That’s the folder where my personal files are stored.

Now that we know where we are, the next logical question is: “What’s here?”

To find out, use the command `ls`. This stands for “list,” and it will show you everything inside the current directory—both files and folders.

Here’s what my terminal shows when I type `ls`:

<!-- 
```
Dmytro@dell-xps-9570:~$ ls  
 'Calibre Library'  Pictures           Projects  
 Desktop            Public             Videos  
 Documents          Downloads          Templates  
 Zotero             Music              Scanned_Document_House.pdf  
``` 
-->

As you can see, I have a mix of directories and one lonely PDF document I prepared for the tax authorities. I recognize all of these files—they’re the same ones I’d see if I opened my Files app and navigated to my user directory.

So, in just two simple commands—`pwd` to figure out where you are and `ls` to see what’s inside—you’ve already gained some control over the terminal. Pretty cool, right?

Now that you know how to figure out where you are on your computer, we’ll take it a step further and learn how to move around the file system using the terminal. 

The command you’ll need is `cd`, which stands for “change directory.” This is how you “step into” a folder or directory from the terminal.

Let’s say you see a folder named Pictures in your current directory, and you want to navigate into it. All you have to do is type:

```
cd Pictures
```

Hit Enter, and you’ll notice that the prefix—the text before the system prompt—changes. This tells you that you’re now inside the Pictures directory.

Want to double-check where you are? Use the `pwd` command again, and it will confirm your new location. If you want to see what’s inside the Pictures folder, just type `ls` again.

But what if you want to go back to where you were before? Easy! Just type:

```
cd ..
```

The two dots (..) mean “go up one level.” Hit Enter, and you’ll be back in the directory you started from.

Let me show you an example of a full roundtrip: cd Pictures - pwd - cd .. - pwd


<!-- 
```
Dmytro@dell-xps-9570:~$ cd Pictures  
Dmytro@dell-xps-9570:~/Pictures$ pwd  
/home/Dmytro/Pictures  
Dmytro@dell-xps-9570:~/Pictures$ cd ..  
Dmytro@dell-xps-9570:~$ pwd  
/home/Dmytro  
``` 
-->

See how simple that was? Using just `cd` and `cd ..`, you can navigate up and down the directory tree.

Now it’s your turn! Play around with these commands. Practice navigating into folders and back out again. There are faster ways to move around your file system, but for now, these basic steps are more than enough to get you started. Once you’re comfortable with these movements, please, take an effort to navigate to the directory, where you decided to store your project files.

<!-- :::{.challenge}
Using `cd`, `cd ..` and `ls`, navigate to the directory, where you decided to store your project files.
::: -->

When you have done that, join me in the next section, where we’ll begin installing some software to set up your data analysis environment. I’ll see you there!

# VIDEO 4 {studio} ~ 3 min

<!-- ## Installing uv -->

Alright, now it’s time to roll up our sleeves and install one of the most exciting tools in modern Python development—uv!

uv is an incredibly fast Python installation and environment manager, written in the high-performance language Rust. This tool burst onto the Python scene earlier this year, and it’s already winning the hearts of Python developers worldwide.

When I say “fast,” I mean lightning fast—orders of magnitude faster than its popular counterparts! Just look at this chart:

<!-- ![](img/uv-perf-chart.png) -->

Not only is uv fast, but it’s also environmentally friendly. Yes, it’s saving the planet! By reducing the time and energy it takes for data centers to rebuild their test and development environments daily, uv contributes to a smaller carbon footprint.

In this course, we’ll only scratch the surface of what uv can do. But I promise, as you start using it in your real-life projects, your appreciation for this tool—and the Astral team behind it—will grow exponentially

Now let’s get started with the installation. Open your terminal and type the following command. 
<!-- 
:::{.challenge}

On Mac or Linux, use the following command after the system prompt:
```
curl -LsSf https://astral.sh/uv/install.sh | sh
``` 

On Windows, type the following:

```
powershell -c "irm https://astral.sh/uv/install.ps1 | iex"
``` 
::: 
-->
Hit Enter, and the installation should begin.

If you already have Python installed, you can also install uv using one of Python’s existing package managers. On Mac, it’s even possible to install it through Homebrew. I’ll include a link to the official documentation with detailed instructions below this video.

<!-- :::{.challenge}
Check out `uv` installation instructions at https://docs.astral.sh/uv/getting-started/installation/
::: -->

Once the installation is complete, let’s check if everything worked. In your terminal, type `uv`. You should see output that looks something like this:

<!-- 
```
uv

#> An extremely fast Python package manager.
#>
#> Usage: uv [OPTIONS] <COMMAND>
#> 
#> Commands:
#>  run      Run a command or script
#>  init     Create a new project
#>  ...
``` 
-->

If you see that, congratulations! You’ve successfully installed uv. 

From now on, we’ll use uv to manage everything, including installing Python itself. Stay with me as we continue setting up your computing environment. I’ll see you in the next section!

# VIDEO 5 {studio} ~ 10 min

<!-- ## Managing python installation -->

uv isn’t just a package and environment manager—it also handles Python installations effortlessly. Let’s start by checking if uv can detect an existing Python installation on your system.

In your terminal, run:

```
uv python find
```

If uv detects a Python installation, it will return the path to it. This path will also likely give you a clue about the Python version. But if you’re unsure about the version, you can use this command:
<!-- 
```
uv python list --only-installed
``` 
-->

Now comes the decision point: Do you want to use your existing Python installation, or would you prefer a fresh installation managed entirely by uv?

Here’s my advice: While you can use the Python installation that uv detects, it’s often a good idea to have a separate Python installation that’s fully under uv's control. Why? Because Python is often deeply integrated into modern operating systems, and having an isolated installation ensures you don’t accidentally disrupt system-level functionality.

Python environment management has historically been a mess! XKCD even made a [famous comic](https://xkcd.com/1987/) about it. 

<!-- ![](https://imgs.xkcd.com/comics/python_environment_2x.png) -->

Yeah, it can get pretty bad. But don’t worry—with uv, that nightmare is a thing of the past. If you’re ready to let uv manage your Python installation, run this command: 

```
uv python install
```

This will install the latest and greatest version of Python, which will now be entirely supervised by uv. If the installation completes without errors, you’re officially set up with Python! To verify, you can run the uv python find command again, and it should show the new Python installation.

With Python sorted, you’re ready for the next step: setting up your project environment. 

As we discussed earlier, every data analysis project should live in its own folder. This keeps things tidy and avoids any cross-contamination between projects. Now, naming your project folder can feel like a challenge—it’s almost an art! Developers joke that naming things is one of the hardest parts of computer science. Why? Because you want a name that’s memorable, descriptive, and easy to type.

So, pick a short, meaningful name without spaces. I’ve decided to call my project data-literacy-project. Once you’ve chosen a name, make sure you’re in the directory where you want to create your project. You can double-check by running `pwd` (`cd` on Windows).  Now, let’s initialize your project. Type the following, replacing `data-literacy-project` with your project’s name:

<!-- 
```
uv init data-literacy-project
cd data-literacy-project
``` 
-->

Note that the second command navigates you into the folder (remember, we learned `cd foldername`). That is because `uv init` has created a new directory for you with the name you picked. There's one command I did not tell you about, which allows you to create directories manually. It is called `mkdir` which stands for "make directory", followed by the directory name. 

If you prefer, you could create the folder yourself and then initialize it with uv. Here’s how that would look:

<!-- 
```
$ mkdir data-literacy-project
$ cd data-literacy-project
$ uv init
``` 
-->

Either way, once you’re inside the folder, it’s ready to go! You can explore what uv has created for you by running `ls`. One of the files you’ll see is pyproject.toml. This is your project’s manifest—a file where uv tracks metadata about your project, including its dependencies (the libraries it needs).

Speaking of dependencies, let’s add some libraries. Run the following commands:

<!-- 
```
$ uv add gapminder plotnine polars pyarrow great_tables
$ uv add --dev setuptools jupyter ipykernel pyyaml nbformat nbclient jupyterlab-quarto
``` 
-->

These commands install several Python libraries we’ll use throughout the course. Here we separated the main packages we need for analysis and visualization (listed here in the first line), from the auxilliary packages used to set up a computing environment, the tools we are going to use. The idea is that your Python code relying on main dependencies may stay the same, while the computing setup may look completely different. In this course we will be using Jupyter notebooks, but the same analysis can be performed in Python script files in an IDE, such as VS Studio Code or Positron.

As you run these commands, you will notice that uv installs more packages than we requested. It pulls in the packages that these specified libraries rely on — it handles all the messy details of software dependecies for you! And thanks to uv, the installation will be lightning-fast.

Curious about what just happened? I want to leave you with a fun little command: it’s called cat. Yes, like the furry little animal! The cat command is a handy way to view the contents of small files directly in your terminal. For larger files, it might take a while to load, but for our purposes, cat is perfect.

Let’s use it to check out the contents of our project manifest file. In your terminal, type:

```
cat pyproject.toml
``` 

When you hit enter, you’ll see something like this:

<!-- 
```yaml
[project]
name = "data-literacy-project"
version = "0.1.0"
description = "Add your description here"
readme = "README.md"
requires-python = ">=3.10"
dependencies = [
    "gapminder>=0.1",
    "great-tables>=0.15.0",
    "plotnine>=0.14.3",
    "polars>=1.17.1",
    "pyarrow>=18.1.0",
]

[tool.uv]
dev-dependencies = [
    "ipykernel>=6.29.5",
    "jupyter>=1.1.1",
    "jupyterlab-quarto>=0.3.5",
    "nbclient>=0.10.1",
    "nbformat>=5.10.4",
    "pyyaml>=6.0.2",
    "setuptools>=75.6.0",
]
``` 
-->

This file, pyproject.toml, serves as a “manifest” for your project. It keeps track of metadata like your project name, version, and—most importantly—dependencies. Each time you add a new library with uv add, it’s recorded here.

Now, here’s something happening behind the scenes: uv created a hidden folder called .venv. This stands for “virtual environment,” and it’s where all your project’s libraries and dependencies live. Hidden files and folders don’t show up when you run `ls`— not unless you add the -a flag to the command, so `ls -a` will, in fact, show that you have this `.venv` folder in your project directory. But don’t worry that this folder stays hidden, you’ll rarely, if ever, need to open it. uv manages this folder for you, so you can focus on your work without getting bogged down in the details.

Here’s the most important thing to know: the .venv folder is what makes your project self-contained. All your dependencies are stored there, safe and separate from anything else on your system. This is especially useful if you want to share your work later—a topic we’ll cover in the final module of this course.

# VIDEO 6 {studio} ~ 12 min
<!-- ## Launch Jupyter -->

Finally, let’s talk about Jupyter, one of the most transformative tools for interactive data analysis.

Jupyter is more than just a tool—it’s a revolutionary concept. It provides a cross-platform environment for literate programming, where code, text, and results coexist seamlessly. Oh, and here’s a fun fact: the name "Jupyter" stands for Julia-Python-R, highlighting its roots as a language-agnostic platform for fast prototyping, experimentation, and sharing results. Today, the Jupyter ecosystem has grown immensely, with thousands of educators, practitioners, and enthusiasts gathering annually at JupyterCon, a conference dedicated to this amazing technology.

At the heart of Jupyter is the Jupyter Notebook, a special format that allows you to write, execute, and save code, alongside text and rich results like visualizations. Behind the scenes, Jupyter maintains a live connection to the execution language—called a kernel. In our case, that’s Python.

Luckily, the uv tool integrates Jupyter as one of its supported engines, making it simple to launch Jupyter Lab, the interactive environment where we’ll be working. To launch Jupyter Lab, type this command in your terminal:

```
uv run --with jupyter jupyter lab
```

When you run this command, your terminal will remain busy while Jupyter Lab is running. It’s a good idea to minimize the terminal and let it work in the background. Shortly after, your default web browser will open, displaying the Jupyter Lab interface.

You’ll see a screen like this:

<!-- ![](img/jlab-1.png) -->

Click the large blue button in the top left corner—or press Ctrl-Shift-L (or Cmd-Shift-L on a Mac)—to open a Launcher.

<!-- ![](img/jlab-2.png) -->

In the Launcher, click the "Python 3 (ipykernel)" button under the "Notebook" section. This will open a new tab in Jupyter Lab, where you’ll see an empty document that looks like this:

<!-- ![](img/jupyterlab-2.png) -->

Now, let’s take a closer look at the Jupyter Notebook interface. A notebook is made up of cells, which can be either code cells or text cells. By default, the first cell is created for you, and it’s set to "code." The cursor will already be placed in the cell, ready for you to start typing Python code.

Let’s try a quick example!

Type the following code into the first cell:
```
from datetime import date
print('Today is', date.today())
```
Press Ctrl-Enter (or Cmd-Enter on a Mac) to execute the code.

<!-- 
:::{.challenge}
Type and execute the following code in the first cell:
```
from datetime import date
print('Today is', date.today())
```
::: 
-->

You’ll see the output—today’s date—appear below the cell. Notice how the cell turns grey, indicating you’ve exited "edit mode" and are now in command mode.

From command mode, you can do all sorts of things:

- Press B to insert a new cell below.
- Press A to insert a cell above.

When you create a new cell, it won’t immediately be in edit mode. It’ll still be greyed out, waiting for further instructions.

Let’s say we want to explain what the code does. For that, we can turn the new cell into a text cell. To change the cell type, press M (for "Markdown"). Markdown is a simple formatting language that lets you write text with styling.

Now, place your cursor in the cell to start typing your thoughts. You can even add styling! For example:

- Surround text with single stars `* text *` for *italics*.
- Use double stars `** text **` to make text **bold**.

Try it out! 

Add a brief description of what the code does, and play around with text formatting. When you’re done editing text in a Markdown cell, press Ctrl-Enter (or Cmd-Enter on a Mac) to render it as rich text. Your formatting—like italics, bold text, or headings—will all be applied instantly.

<!-- 
:::{.challenge}
Add a description of what the code does, use text formatting. Conclude with Ctrl-Enter (or Cmd-Enter on a Mac) to render it. 
::: 
-->

If you want to switch a Markdown cell back to code mode, it’s simple: press Y while in command mode. Now, the cell will behave like a code cell. Be cautious, though! If you type something invalid, the notebook will produce an error when you try to execute it.

To exit edit mode and return to command mode, press the Esc key on your keyboard. Once in command mode, you can navigate through cells using the arrow keys. This is helpful when you want to scroll through your notebook, locate a specific section, or insert new cells either above (A) or below (B).

To help you work more efficiently, here’s a pro tip: Jupyter Notebooks come with a host of useful shortcuts. Don’t worry, we’ll leave a list for you to refer to later.

In the next module, you’ll use this environment to create stunning data visualizations. While it’s technically possible to write all your code in a single cell, it’s not recommended. You’ll soon learn that breaking your code into smaller, modular sections makes debugging much easier. Plus, combining code cells with text cells lets you document your thoughts, findings, and learning process.

Think of your notebook as exactly that—a notebook. Use it as a space for both experimentation and documentation. Interleave your code and text, and add section titles as you move through new chapters. In the final module, we’ll explore how to turn your notebook into a polished, professional report. So start structuring your work now, aiming for clarity and organization from the beginning.

I encourage you to play around with Jupyter Notebook! Try simple arithmetic operations in code cells and add comments in Markdown cells below them. Experiment with switching cell types, adding formatting, and organizing your notebook.

<!-- 
:::{.challenge}
- Add a code cell, write Python code to perform simple arithmetic operations.
- Add comments in a Markdown cell. Adding formatting
- Add structure to your notebook using headers of different levels.
::: 
-->

When you’re ready to save your work, press Ctrl-S (or Cmd-S on Mac). Be sure to give your notebook a meaningful name and keep the file extension as .ipynb. This tells your system that the file is a Jupyter Notebook. I hope you have fun exploring this amazing tool! Jupyter notebooks are powerful, versatile, and central part of modern data analysis toolset. 

And that’s it! The boring setup part is officially behind us. From here on, it’s all about diving into the exciting world of data analysis. Onward and upward!